	<!doctype html>
<html lang="en">
  <head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWPB63L');</script>
<!-- End Google Tag Manager -->
	  
 <!-- need an ID !!!! remeber to apply an ID !!!!!!!!!!!! -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'GA_MEASUREMENT_ID');
</script>    

<script>
function showHideNews() {
    var x = document.getElementById("extraNews");
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>
	  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1"/>
    <meta name="description" content="" />
    <meta name="author" content="Tao Chen|Design intelligent sensing and mobile for societal good">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="style.css" rel="stylesheet">  
	  <script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>

    <link rel="icon" type="image/png" href="data/images/tao_icon.png">
    <title>Tao Chen|AI for sound,sensor,and health</title>
  </head>

  <body>
  
	<!-- Google Tag Manager (noscript) -->
	<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWPB63L"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<!-- End Google Tag Manager (noscript) -->	  
    <div class = "global_container">
      <div class = "section"  >  
      <h1></h1> 
      <h1></h1>
      <div class="row no-gutters">
        <div class ="col-5 col-md-3">
        <div class = "white_boxed">
<!--         <img class="scale_img" src="data/images/tao_2023.jpg"> -->
	<img class="scale_img" src="data/images/tao_chen_miami.jpg">
        </div>
        </div>	      
        <div class ="col-7 col-md-7">
          <div class = "white_boxed">
          <h5>Tao Chen</h5>	  		  
          <p> </p>
          <p> Senior Researcher <br>
          Samsung Research America <br>
          <p>Email: tachen.cs@gmail.com </p>
          <p> <a href="https://scholar.google.com/citations?user=C6RUzpEAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar</a> / <a href="https://www.linkedin.com/in/tao-chen-8327301a3/" target="_blank" rel="noopener">LinkedIn</a> / <a href="https://github.com/tachen-cs" target="_blank" rel="noopener">Github</a> / <a href="https://orcid.org/0000-0003-4565-5548" target="_blank" rel="noopener">ORCID</a></p>
<!-- 	   <p> <i>Design intelligent sensing and mobile for societal good.</i> </p> -->
<!-- 	  <p> <i>AI for sound, sensing, and multi-modal signals.</i> </p> -->
<!-- 	  <p> <i>AI for sound, wearable, and multi-modal agent.</i> </p> -->
<!-- 	  <p> <i>Building sensory AI for perceiving and interpreting physical world.</i> </p> -->
<!-- 	  <p> <i>Building sensory AI serving for human and physical world.</i> </p> -->
		<p> <i>Ambient intelligence. </i> </p>
			  <!-- 	  <p> <i>Multi-modal sensor intelligence. </i> </p> -->
<!-- 	  <p> <i>Sensor intelligence systems. </i> </p> -->
<!-- 	  <p> <font color="#c03c3b"> I am on the job market this season and appreciate any fit opportunity. </font> </p> -->
	  </div>
        </div> 
        </div>         
                  
	<h1></h1> 
	<h4>News </h4>
       <hr color=#F1ECEC size="1">
      	<div class ="boxed">
		<p>[Aug, 2025] One paper accepted by BSN'25. </p>
		<p>[May, 2025] LeekyFeeder accepted by SenSys'25 and won <font color="#FF0000"><strong>Best Paper Award Nominees</strong></font>. </p>
		<p>[Jan, 2025] Our group had an exciting opportunity to visit Senegal, Africa, to deploy low-cost hearable health monitors for <a href="data/images/afria.jpg" target="_blank" rel="noopener">supporting local underserved communities</a>. </p>
		<p>[Nov, 2024] Asclepius won <font color="#FF0000"><strong>Best Paper Award</strong></font> at MobiCom 2024 and I was invited to present it at both main conference and AgeTech workshop. </p>
		<p>[Nov, 2024] "Earable Multimodal Sensing and Stimulation: A Prospective Towards Unobtrusive Closed-Loop Biofeedback" accepted by IEEE Reviews in Biomedical Engineering. </p>
		<p>[Nov, 2024] Vision paper "Towards Next-Generation Human Computer Interface Based On Earables" now accepted by IEEE Pervasive Computing.</p>
		<p>[Jul, 2024] Zero-shot IoT sensing with foundation models now accepted by ECAI'24.</p>
		<p>[Mar, 2024] EarVoice is now accepted by MobiSys'24 :) </p>
		<p>[Jan, 2024] Mobile Acoustic Field (MAF) is accepted by CHI'24. </p>
<!-- 		<p>[Dec, 2023] One acoustic paper is currently under one-shot revision at NSDI'24. </p> -->
		<p>[Nov, 2023] <a href="https://asclepius-system.github.io/" target="_blank" rel="noopener">Asclepius</a> and MagWear are both accepted by MobiCom'24. See you in DC next year! </p>
		<!-- <p>[Sep, 2023] Invited to serve the TPC of ICPADS'23, MobiQuitous'23. </p> -->
		<!-- <p>[Jun, 2023] Invited to serve the AEC of MobiCom'23, NDSS'24, SOSP'23. </p> -->
		<p>[Jun, 2023] Happy to receive the Best Poster Presentation Award (12/300+) at <a href="https://www.oacd.health.pitt.edu/content/postdoctoral-data-dine-symposium" target="_blank" rel="noopener">Pitt Postdoctoral Symposium 2023</a>!
<!-- 		<p>[May, 2023] Pitt SCI covers <a href="https://www.sci.pitt.edu/news/earable-computers" target="_blank" rel="noopener">our research on earable</a>! -->
<!-- 		<p>[Feb, 2023] SoundSticker is accepted by ToSN, checkout the <a href="https://soundsticker.github.io/" target="_blank" rel="noopener">website</a> for the demo and audio clips! </p> -->
<!-- 		<p>[Dec, 2022] Invited to serve as the TPC of IEEE Cloud Summit 2023! </p> -->
		<p>[Dec, 2022] Humbled to receive the ACM SIGMOBILE Student Community Grant award! </p>
  	</div>

	<h1></h1>   
	      <h4> Research </h4>
      	<hr color=#F1ECEC size="1">
	      <div class ="boxed">
<!-- 	      <p>
		I am an audio expert focusing on <strong>human-centric acoustics</strong>. My research aims to unlock the untapped potential of sound through cutting-edge AI, sensing, and computational technologies. 
		Sound, a fundamental element in our world, is a potent force that offers rich insights into our physiology, environment, and interactions.
		My work tries to uncover these new dimensions in the comprehension and utilization of sound within the mobile sphere. 
		This includes analyzing <strong>in-body sounds</strong> for healthcare advancements, enhancing interactions through <strong>sound-sensitive devices</strong> (like earphones) <strong> and speech </strong>,
		and protecting <strong>environmental acoustics</strong>. 
		Ultimately, my research endeavors to transform the role of sound in technology and everyday life, making it more integral and interactive. </p>
		
	      <p>
		I am currently building next-gen wearable AI on earphones.
	      </p>
 -->
	<!-- 2025 version -->
<!-- 		      health, safety features-->
	      
	 <p>
		My research is driven by the vision of ambient intelligence, aiming to enable novel perception and AI accessibility anytime, anywhere. 
		 I am working on this vision by developing technologies that empower current consumer/redefine the future of, computing devices to help users in the true sense and improve user health, wellness, and safety.
	</p>	
     <p>
		 My past innovations span, but are not limited to following personal wearable and home hardware lines:
		 <br> <b>Smart speakers</b> (NDSS’20, ToSN, MobiCom’23)
		 <br> <b>Phones</b> (ICDCS’20, ECAI'24)
		 <br> <b>Earbuds</b> (MobiCom’24, CHI’24, SenSys’25, MobiSys’24, BSN’25)
		 <br> <b>Wristbands</b> (MobiCom’24)
		 <br> and emerging AI home devices yet to come. This track record is recognized by a MobiCom Best Paper Award and a SenSys Best Paper Nominee.
	 </p>
		 
			  
			  
	  <!-- <p>	  
		<!-- I am an experimental computer system researcher. My research centers on building human-centric mobile system, aims to bring novel perception and ambient intelligence to wearable devices through cutting-edge AI, sensing, and computational technologies.  -->
		<!-- I take pride in building systems that function effectively in the physical world. My approach is usually end-to-end, encompassing sensors, embedded systems, signal processing, and AI/ML models.
		and the perceive and interact with the physical world.-->
	        <!-- Passionate about sensor + ML technology, I currently work on the following areas to create intelligent systems and applications:
	         <br>
	         <br> <b>- Digital health:</b> Asclepius(MobiCom'24,<font color="#FF0000"><strong>Best Paper</strong></font>), Magwear(MobiCom'24), Zero-shot activities logging(ECAI'24), Earable(RBME'24), CLEAR-APG(BSN'25)
		 <br> <b>- Audio, sensory, physical AI:</b> EarVoice(MobiSys'24), SpotSound(MobiCom'23), SoundSticker(ToSN), Metamorph(NDSS'20), TapLeak(ICDCS'20) 
		 <br> <b>- Spatial computing:</b> MAF(CHI'24), LeekyFeeder(SenSys'25,<font color="#FF0000"><strong>Best Paper Nominees</strong></font>)
	          -->
	      <!-- </p>  -->
		      
	      <p>
		 <b><i>I am always open to collaborations. If you see any interest, feel free to drop an email and I am happy to chat!</i> </b>
	      </p>      
		      
	      </div>
	      
        <h1></h1>
    		<h4> Short Bio </h4>
        <hr color=#F1ECEC size="1">
        
	      <div class ="boxed">
<!-- 		I care about IoT systems, especially acoustic things. The classical air-conducted sounds, acoustic signals spread among body, robotics, and even underwater are all my interests. 
My toolkits include theoretical acoustic modeling, hardware design, signal processing and machine learning methodologies. -->
<!-- 		My research is about building systems on the intersection of Mobile Computing and IoT system. I feel motivated to enable new inteillgient automation using sensors data and communication parades, meanwhile protecting people from the "seemingly" innocuous automation. Currently, I am intersted in acoustic signals and devices.   -->
		  
<!-- 		  My broad research interests lie in the areas of mobile computing, signal processing and embedded system design.
My vision is to develop human-centric communication, networking, sensing and computation technologies on commercial mobile, wearable and customized hardware devices for strengthening human convenience, intelligence, health and safety in our society.
Currently, I focuses on developing novel systems and applications interacted with <strong>acoustic signals and things</strong>, ranges from earable, voice-controlled interfaces, to commodity smartphones. -->
<!--  I am a sensory AI expert and building end-to-end systems for sensing and interpreting the digital world: 1.digital health (Neural Computing), 2.sensory/embodied AI, 3. interaction tech    -->
<!-- I am a sensing system researcher who builds sensory AI systems to perceive and interact with the physical world. I build sensory AI systems end to end and am interested in any sensor technologies. 
My sensory AI systems now focus on the following key topics:
digital/wearable health (perception people)
Sensory/Embodied AI (understand the world to help people, sensor for robot)
HCI (sensor for human)	       -->

	      
<p>
I am currently a senior researcher at Samsung Research. Before that, I was a postdoc at the University of Pittsburgh working with 
Prof. <a href="https://shanggdlk.github.io/" target="_blank" rel="noopener">Longfei Shangguan</a>. Prior to my postdoc, 
I received my Ph.D. from City University of Hong Kong, under the supervision of Prof. 
<a href="http://www.cs.cityu.edu.hk/~zhenjili/" target="_blank" rel="noopener">Zhenjiang Li</a>.
	
</p>
<p> I am a quick learner, easily adapt to new things, and get the job done. </p>
<!-- <p>
I am driven by a commitment to design intelligent sensing and mobile systems that make meaningful contributions to societal well-being.
Currently, my primary focus revolves around advancing healthcare for the greater good, with a keen exploration of health equity and accessibility.
Simultaneously, I am dedicated to enhancing mobile and wearable security through the implementation of cutting-edge technologies.
</p> -->
		      
 <!-- <p> I am a passionate experimental researcher and a full-stack engineer, currently working on projects to explore <b>health equity, accessibility, and convenience</b> as a postdoc researcher at the University of Pittsburgh, working with Prof. <a href="https://shanggdlk.github.io/" target="_blank" rel="noopener">Longfei Shangguan</a>. Prior to my postdoc, 
	 I received my Ph.D. from City University of Hong Kong, under the supervision of Prof. <a href="http://www.cs.cityu.edu.hk/~zhenjili/" target="_blank" rel="noopener">Zhenjiang Li</a>.		      
 </p>  -->

<!-- <p> I find myself at the crossroads of wearable sensing and intelligent mobile systems, always eager to explore the interconnected worlds of software/hardware co-design, signal processing, and applied machine learning. My passion particularly lies in the realms of acoustic and speech signals and the devices associated with them, such as hearables, smart speakers, phones, etc.
</p> 
<p> As a researcher, I enjoy pushing the boundaries of various research disciplines. I invent novel sensing technologies and mobile systems for healthcare and human-computer interactions and stand firmly committed to harnessing technology for the greater good, ensuring robust security and safeguarding privacy in our rapidly evolving cyber-physical world.
As an adept engineer, I excel in system integration, creating comprehensive end-to-end systems with a blend of multi-disciplinary skills, such as fast prototyping, customized circuit design, embedded system programming, signal processing, and machine learning. These skills led my research works to proof-of-concept demos and prototypes. I am a fast learner, easily adapt to new things, and get the job done.
</p>
 -->


          <!--  -->

        </div>

	    
        <h1></h1> 
        <h4>Main Publications </h4>	
        <p class="right_pad"><font color="gray">  (^ represents for students I supervise)</font></p>
        <hr color=#F1ECEC size="1"> 
        <div class = "no_boxed">

          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2025-bsn-clearapg.jpg' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[BSN'25] </font>Heart Rate Monitoring Through ANC Headphones in Unconstrained Environments</p>
              <p class="small"> Zhenyu Wu<sup>^</sup>, Maanya Shanker<sup>^</sup>, <strong>Tao Chen</strong>, Xiaoran Fan, Longfei Shangguan</p>
	      <p class="small"><a href="https://sigmobile.org/mobicom/2024/" target="_blank" rel="noopener"><em>BSN 2025</em> </a>,LA, USA, Nov 2025 </p>
              <p class="small">  
                <a href="https://dl.acm.org/doi/10.1145/3715014.3722054" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>
			
		
          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2025-sensys-leekyfeeder.png' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[SenSys'25] </font>LeekyFeeder: In-Air Gesture Control Through Leaky Acoustic Waves</p>
              <p class="small"> Yongjie Yang<sup>^</sup>, <strong>Tao Chen</strong>, Zhenlin An, Shirui Cao, Xiaoran Fan, Longfei Shangguan</p>
	      <p class="small"><a href="https://sigmobile.org/mobicom/2024/" target="_blank" rel="noopener"><em>SenSys 2025</em> </a>,Irvine, USA, May 2025 </p>
<!--               <p class="small"><a href="https://sigmobile.org/mobicom/2024/" target="_blank" rel="noopener"><em>SenSys 2025</em> </a>,Irvine, USA, May 2025 <font color="#FF0000"><strong>Best Paper Award</strong></font> </p> -->
              <p class="small">  
		<a href="https://leekyfeeder.github.io/results/" target="_blank" rel="noopener">[Demo]</a> &nbsp;&nbsp; 
                <a href="https://dl.acm.org/doi/10.1145/3715014.3722054" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; 
                <a href="data/papers/2025-sensys-leakyfeeder/LeakyFeeder-SenSys.pptx">[Slides]</a> &nbsp;&nbsp;  
              </p>
	      <p class="small"> <font color="#FF0000"><strong>Best Paper Award Nominee</strong></font> </p>  
            </div>
            </div>
            </div>


		

          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2024-mobicom-asclepius.jpg' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[MobiCom'24] </font>Exploring the Feasibility of Remote Cardiac Auscultation Using Earphones</p>
              <p class="small"> <strong>Tao Chen</strong>, Yongjie Yang, Xiaoran Fan, Xiuzhen Guo, Jie Xiong, Longfei Shangguan</p>
	      <p class="small"><a href="https://sigmobile.org/mobicom/2024/" target="_blank" rel="noopener"><em>MobiCom 2024</em> </a>, D.C., USA, Oct 2024 </p>
<!--               <p class="small"><a href="https://sigmobile.org/mobicom/2024/" target="_blank" rel="noopener"><em>MobiCom 2024</em> </a>, D.C., USA, Oct 2024 <font color="#FF0000"><strong>Best Paper Award</strong></font> </p> -->
              <p class="small">  
		<a href="https://asclepius-system.github.io/" target="_blank" rel="noopener">[Project]</a> &nbsp;&nbsp; 
                <a href="data/papers/2024-mobicom-asclepius/mobicom24-final263.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; 
                <a href="data/papers/2024-mobicom-asclepius/TaoChen_asclepius_mobicom_9min_final 2.pdf">[Slides]</a> &nbsp;&nbsp;  
                <a href="https://tachen-cs.github.io/">[Video]</a> &nbsp;&nbsp; 
              </p>
	      <p class="small"> <font color="#FF0000"><strong>Best Paper Award (1 out of all submissions)</strong></font> </p>  
	    <p class="small"> <font color="#FF0000"><strong>ACM SigMobile Research Highlight</strong></font> </p>
            </div>
            </div>
            </div>


          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2024-earvoice-mobisys.jpg' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[MobiSys'24] </font>Enabling Hands-Free Voice Assistant Activation on Earphoness</p>
              <p class="small"> <strong>Tao Chen</strong>, Yongjie Yang, Chonghao Qiu, Xiaoran Fan, Xiuzhen Guo, Longfei Shangguan</p>
              <p class="small"><a href="https://www.sigmobile.org/mobisys/2024/" target="_blank" rel="noopener"><em>MobiSys 2024</em> </a>, Tokyo, Japan, June 2024 </p>
              <p class="small">  
		<a href="https://asclepius-system.github.io/" target="_blank" rel="noopener">[Project]</a> &nbsp;&nbsp;
                <a href="data/papers/2024-mobisys-earvoice/earvoice.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; 
                <a href="https://tachen-cs.github.io/">[Slides]</a> &nbsp;&nbsp;  
                <a href="https://tachen-cs.github.io/">[Video]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>

          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/papers/2024-rmbe-earable/earable_survey.png' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[RBME] </font>Earable Multimodal Sensing and Stimulation: A Prospective Towards Unobtrusive Closed-Loop Biofeedback</p>
              <p class="small"> Yuchen Xu, Abhinav Uppal, Min Suk Lee, Kuldeep Mahato, Brian L. Wuerstle, Muyang Lin, Omeed Djassemi, <strong>Tao Chen</strong>, Rui Lin, Akshay Paul, Soumil Jain, Florian Chapotot, Esra Tasali, Patrick Mercier, Sheng Xu, Joseph Wang, Gert Cauwenberghs</p>
	      <p class="small"><a href="https://www.embs.org/rbme/" target="_blank" rel="noopener"><em>IEEE Reviews in Biomedical Engineering</em> </a>, IF:17.20 </p>
              <p class="small">  
                <a href="data/papers/2024-rmbe-earable/RBME3508713_final_proof.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; 
                <a href="https://tachen-cs.github.io/">[Video]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>		
		
          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/papers/2024-pervasive-compute/p.PNG' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[Pervasive] </font>Towards Next-Generation Human Computer Interface Based On Earables</p>
              <p class="small"> Yongjie Yang<sup>^</sup>, <strong>Tao Chen</strong>, Longfei Shangguan</p>
	      <p class="small"><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7756" target="_blank" rel="noopener"><em>IEEE Pervasive Computing</em> </a> </p>
              <p class="small">  
                <a href="https://tachen-cs.github.io/" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>			

          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/papers/2024-ecai-zero/0shot.png' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[ECAI] </font>Leveraging Foundation Models for Zero-Shot IoT Sensing</p>
              <p class="small"> Dinghao Xue<sup>^</sup>, Xiaoran Fan, <strong>Tao Chen</strong>, Guohao Lan, Qun Song</p>
	      <p class="small"><a href="https://www.ecai2024.eu/" target="_blank" rel="noopener"><em>European Conference on Artificial Intelligence</em> </a> </p>
              <p class="small">  
                <a href="https://arxiv.org/abs/2407.19893" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp;
	        <a href="https://github.com/schrodingho/FM_ZSL_IoT" target="_blank" rel="noopener">[Code]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>
		
          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2024-chi-maf.jpg' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[CHI'24] </font>MAF: Exploring Mobile Acoustic Field for Hand-to-Face Gesture Interactions</p>
              <p class="small"> Yongjie Yang<sup>^</sup>, <strong>Tao Chen</strong>, Zipan Huang, Xiuzhen Guo, Longfei Shangguan</p>
              <p class="small"><a href="https://chi2024.acm.org/" target="_blank" rel="noopener"><em>CHI 2024</em> </a>, Hawaiʻi, USA, May 2024 </p>
              <p class="small">  
		<a href="https://asclepius-system.github.io/" target="_blank" rel="noopener">[Project]</a> &nbsp;&nbsp; 
                <a href="data/papers/2024-chi-maf/chi24-maf.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp;     
                <a href="https://tachen-cs.github.io/">[Slides]</a> &nbsp;&nbsp;  
                <a href="https://tachen-cs.github.io/">[Video]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>




		
          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2024-mobicom-magwear.jpg' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[MobiCom'24] </font>Exploring Biomagnetism for Inclusive Vital Sign Monitoring: Modeling and Implementation</p>
              <p class="small">Xiuzhen Guo, Long Tan, <strong>Tao Chen</strong>, Chaojie Gu, Yuanchao Shu, Shibo He, Jiming Chen, Longfei Shangguan</p>
              <p class="small"><a href="https://sigmobile.org/mobicom/2024/" target="_blank" rel="noopener"><em>MobiCom 2024</em> </a>, D.C., USA, Oct 2024 </p>
              <p class="small">        
                <a href="https://tachen-cs.github.io/">[Paper]</a> &nbsp;&nbsp;    
                <a href="https://tachen-cs.github.io/">[Slides]</a> &nbsp;&nbsp;  
                <a href="https://tachen-cs.github.io/">[Video]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>

		
          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2022-mobicom-spotsound.jpg' height="100px" width="50px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[MobiCom'23] </font>Towards Spatial Selection Transmission for Low-end IoT devices with SpotSound</p>
              <p class="small">Tingchao Fan<sup>^</sup>, Huangwei Wu<sup>^</sup>, Meng Jin, <strong>Tao Chen</strong>, Longfei Shangguan, Xinbing Wang, Chenghu Zhou </p>
              <p class="small"><a href="https://sigmobile.org/mobicom/2023/" target="_blank" rel="noopener"><em>MobiCom 2023</em> </a>, Madrid, Spain, Oct 2023 </p>
              <p class="small">        
                <a href="https://dl.acm.org/doi/10.1145/3570361.3592496">[Paper]</a> &nbsp;&nbsp;    
                <a href="https://tachen-cs.github.io/">[Slides]</a> &nbsp;&nbsp;  
                <a href="https://tachen-cs.github.io/">[Video]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>


        <div class="row no-gutters align-items-start">
          <div class ="col-3 col-md-3">
          <div class = "white_boxed">
            <img class="scale_img_100" src='data/images/2022-tosn-soundsticker.jpg' height="100px" width="50px">
          </div>
          </div>
          <div class ="col-9 col-md-9">
          <div class = "white_boxed">
            <p class="small"><font color="#c03c3b">[ToSN] </font>The Design and Implementation of a Steganographic Communication System over In-Band Acoustical Channels</p>
            <p class="small"><strong>Tao Chen</strong>, Longfei Shangguan, Zhenjiang Li, Kyle Jamieson </p>
            <p class="small"><a href="https://dl.acm.org/journal/tosn" target="_blank" rel="noopener"><em>ACM Transactions on Sensor Networks</em> </a> </p>
            <p class="small">        
              <a href="https://soundsticker.github.io/" target="_blank" rel="noopener">[Project]</a> &nbsp;&nbsp; 
<!--               <a href="https://dl.acm.org/doi/10.1145/3587162" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp; -->
	      <a href="data/papers/soundsticker.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp;    
              <a href="https://tachen-cs.github.io/">[Slides]</a> &nbsp;&nbsp;  
              <a href="https://www.youtube.com/watch?v=RKyVIddkluA" target="_blank" rel="noopener">[Video]</a> &nbsp;&nbsp; 
            </p>
          </div>
          </div>
          </div>


        <div class="row no-gutters align-items-start">
        <div class ="col-3 col-md-3">
        <div class = "white_boxed">
          <img class="scale_img_100" src='data/images/2020-ndss-adversarialExample.jpg' height="100px" width="50px">
        </div>
        </div>
        <div class ="col-9 col-md-9">
        <div class = "white_boxed">
          <p class="small"><font color="#c03c3b">[NDSS'20] </font>Metamorph: Injecting Inaudible Commands into Over-the-air Voice Controlled Systems</p>
          <p class="small"><strong>Tao Chen</strong>, Longfei Shangguan, Zhenjiang Li, Kyle Jamieson </p>
          <p class="small"><a href="https://www.ndss-symposium.org/" target="_blank" rel="noopener"><em>NDSS Symposium 2020</em> </a>, San Diego, CA, February 2020 </p>
          <p class="small">       
            <a href="https://acoustic-metamorph-system.github.io/" target="_blank" rel="noopener">[Project]</a> &nbsp;&nbsp; 
            <a href="data/papers/2020-metamorph-ndss/Metamorph_CameraReady.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp;    
            <a href="data/papers/2020-metamorph-ndss/Metamorph-Slides.pdf" target="_blank" rel="noopener">[Slides]</a> &nbsp;&nbsp;  
            <a href="https://www.youtube.com/embed/4NSpwiXMbtc">[Video]</a> &nbsp;&nbsp; 
          </p>
          <!-- <p class="small"> <i><font color="#c03c3b">One of the top 4 security conferences</font> </i> </p> -->
        </div>
        </div>
        </div>

        <div class="row no-gutters align-items-start">
          <div class ="col-3 col-md-3">
          <div class = "white_boxed">
            <img class="scale_img_100" src='data/images/2020-icdcs-tapleak.jpg' height="100px">
          </div>
          </div>
          <div class ="col-9 col-md-9">
          <div class = "white_boxed">
            <p class="small"><font color="#c03c3b">[ICDCS'20] </font>Mobile Phones Know Your Keystrokes through the Sounds from Finger's Tapping on the Screen</p>
            <p class="small">Zhen Xiao<sup>^</sup>, <strong>Tao Chen</strong>, Yang Liu, Zhenjiang Li</p>
            <p class="small"><a href="https://icdcs2020.sg/" target="_blank" rel="noopener"><em> IEEE ICDCS </em> </a>, Singapore, December 2020 </p>
            <p class="small">       
              <a href="data/papers/2020-icdcs-tapleak/icdcs.pdf" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp;    
              <a href="data/papers/2020-icdcs-tapleak/2020-ICDCS-TapLeak-slides.pdf" target="_blank" rel="noopener">[Slides]</a> &nbsp;&nbsp;  
              <a href="https://www.youtube.com/embed/4NSpwiXMbtc">[Video]</a> &nbsp;&nbsp; 
            </p>
            <p class="small"> <i><font color="#c03c3b">[TMC]</font> Journal version in IEEE Transactions on Mobile Computing</i></p>            
          </div>
          </div>
          </div>

          <div class="row no-gutters align-items-start">
            <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/2020-survery.png' height="100px">
            </div>
            </div>
            <div class ="col-9 col-md-9">
            <div class = "white_boxed">
              <p class="small"><font color="#c03c3b">[IOTJ] </font>Adversarial Attacks and Defenses on Cyber-Physical Systems: A Survey</p>
              <p class="small">Jiao Li, Yang Liu, <strong>Tao Chen</strong>, Zhen Xiao, Zhenjiang Li, Jianping Wang</p>
              <p class="small"><a href="https://ieee-iotj.org/" target="_blank" rel="noopener"><em> IEEE Internet of Things Journal </em> </a></p>
              <p class="small">       
                <a href="https://ieeexplore.ieee.org/document/9006862" target="_blank" rel="noopener">[Paper]</a> &nbsp;&nbsp;    
                <a href="data/papers/2020-icdcs-tapleak/2020-ICDCS-TapLeak-slides.pdf" target="_blank" rel="noopener">[Slides]</a> &nbsp;&nbsp;  
                <a href="https://www.youtube.com/embed/4NSpwiXMbtc">[Video]</a> &nbsp;&nbsp; 
              </p>
            </div>
            </div>
            </div>


        </div>

      <h1></h1> 
    <h4>Other Publications </h4> 
    <hr color=#F1ECEC size="1"> 
    <div class ="boxed">

      <p class="small">
        <a href="https://dl.acm.org/doi/abs/10.1145/3733892.3733898" target="_blank" rel="noopener">Cardiac Auscultation with Earphones</a></p>
      <p class="small"><strong>Tao Chen</strong>, Yongjie Yang, Xiaoran Fan, Xiuzhen Guo, Jie Xiong, Longfei Shangguan </p>
      <p class="small"><a href="https://dl.acm.org/toc/sigmobile-getmobile/2025/29/1" target="_blank" rel="noopener"><em>GetMobile: Mobile Computing and Communications</em> </a></p>
	    <br>
	    
      <p class="small">
        <a href="https://dl.acm.org/doi/abs/10.1145/3560905.3568084" target="_blank" rel="noopener">Towards Remote Auscultation With Commodity Earphones</a></p>
      <p class="small"><strong>Tao Chen</strong>, Xiaoran Fan, Yongjie Yang, Longfei Shangguan </p>
      <p class="small"><a href="https://sensys.acm.org/2022/" target="_blank" rel="noopener"><em>SenSys 2022</em> </a>, Boston, USA, November 2022 </p>
	    <br>
      
      <p class="small">
        <a href="https://www.ndss-symposium.org/wp-content/uploads/2020/02/NDSS2020posters_paper_14.pdf" target="_blank" rel="noopener">Poster: Room-Scale Over-the-Air Audio Adversarial Examples </a></p>
      <p class="small"><strong>Tao Chen</strong>, Longfei Shangguan, Zhenjiang Li, Kyle Jamieson </p>
      <p class="small"><a href="https://www.ndss-symposium.org/" target="_blank" rel="noopener"><em>NDSS Symposium 2020</em> </a>, San Diego, USA, February 2020 </p>
	    
    </div>

  <h1></h1>
    <h4> Patents </h4>
    <hr color=#F1ECEC size="1">
  <div class ="boxed">
	  
	<p> <a href="https://patentscope.wipo.int/search/en/WO2025019404" target="_blank" rel="noopener"> CARDIAC AUSCULTATION USING EARPHONES </a> </p>
    <p> <a href="https://patentscope.wipo.int/search/en/WO2025188612" target="_blank" rel="noopener"> PROCESSING OF AUDIO SIGNALS FROM EARPHONES FOR INTERACTIVITY WITH VOICE-ACTIVATED APPLICATIONS </a> </p>
	<p> <a href="https://patentscope.wipo.int/search/en/WO2025188615" target="_blank" rel="noopener"> DETECTING HAND GESTURES IN MOBILE ACOUSTIC FIELDS AROUND BONE CONDUCTION HEADPHONES </a> </p>
	<p> <a>  Defense Method of Adversarial Voice Commands Based on Digital Signature </a> </p>
  </div>

    <h1></h1>
    <h4> Selected Awards </h4>
    <hr color=#F1ECEC size="1">
  <div class ="boxed">
	  
    <p> <a href="data/images/best_sensys25.jpg" target="_blank" rel="noopener"><font color="#FF0000"><strong>Best Paper Award Nominees</strong></font></a>, ACM SenSys, 2025</p>
    <p> <b>ACM SigMobile Research Highlight</b>, 2025</p>
    <p> <a href="data/images/bestpaper_mobicom24.jpg" target="_blank" rel="noopener"><font color="#FF0000"><strong>Best Paper Award (1 out of all submissions)</strong></font></a> , ACM MobiCom, 2024</p>
    <p> <b>SIGMOBILE Student Community Grant Award</b>, ACM SIGMOBILE, 2022</p>
    <p> <b>Best Poster Presentation Award (12/300+)</b>, Pitt Postdoctoral Research Symposium, 2023</p>
    <p> <b>Student Travel Grant</b>, NDSS, 2020</p>
    <p> <b>Research Tuition Scholarship</b>, CityU, 2020</p>
    <p> <b>Robosub Best New Team</b>, AUVSI and ONR, 2016</p>
    <p> <b>Singapore AUV Challenge First Place</b>, IEEE OES Singapore, 2016</p>
    <p></p>
  </div>

    <h1></h1>
    <h4> Talks, Lectures & Presentations </h4>
    <hr color=#F1ECEC size="1">
  <div class ="boxed">   
    <p> <b>Exploring the Feasibility of Remote Cardiac Auscultation Using Earphones </b>
     <br> - ACM MobiCom 2024
     <br> - MobiCom4AgeTech workshop 2024
     <br> - Carnegie Mellon University, hosted by Prof. Mahadev Satyanarayanan </p>
    <p> <b>Audio and Beyond: Building Multimodal Sensory AI Systems</b>
     <br> - University of Pittsburgh
     <br> - Samsung Research America
     <br> - Starkey Hearing Technologies
     <br> - Dolby Laboratories Inc
     <br> - Apple
     <br> - AIZIP </p>
    <p> <b>Sensing and Interpretation: Push the Limit of Accessible Consumer Health</b>  
     <br> - University of Pittsburgh
     <br> - Samsung Research America </p>
    <p> <b>Enabling Hands-Free Voice Assistant Activation on Earphones</b>       
     <br> - Carnegie Mellon University, hosted by Prof. Mahadev Satyanarayanan </p>
    <p> <b>Exploring Biomagnetism for Inclusive Vital Sign Monitoring: Modeling and Implementation</b>       
     <br> - Carnegie Mellon University, hosted by Prof. Mahadev Satyanarayanan </p>
  </div>
	      

	<h1></h1>
	<h4> Services </h4>
	<hr color=#F1ECEC size="1">
	    <div class ="boxed">
		     <p> <b>Editor:</b> 
		     <br> Electronics: Recent Advances in Signal Processing for Flexible and Wearable Electronics (Special Issue) </p>
		    <p> <b>TPC:</b> 
		     <br> 2025: HumanSys; MobiSys (AEC), 
		     <br> 2024: ISWC; MobiCom (AEC); NDSS (AEC); IPSN (Poster); IEEE ICPADS; EAI MobiQuitous; EarComp; IEEE MSN; ACM BigCom; IEEE ISPA; SENSORDEVICES;
		     <br> 2023:	MobiCom (AEC); SOSP (AEC); IEEE ICPADS; EAI MobiQuitous; EarComp; IEEE Cloud Summit;
		     <br> 2022: IEEE ICPADS; EAI MobiQuitous; ACM SenSys (shadow); </p>
		    <p> <b>Reviewer:</b> 
		      <br> ACM CHI 2025, 2023;
		      <br> ACM BigCom 2024; 
		      <br> ACM ICDCS 2024; 
		      <br> ACM ASSETS 2023;
		      <br> IEEE VIS 2023;
		      <br> ACM MobiCom 2025, 2024, 2023, 2022, 2021;	    
		      <br> The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT/UbiComp), 2025, 2024, 2023, 2021;
		      <br> IEEE Transactions on Mobile Computing;
		      <br> ACM Transactions on Privacy and Security;
		      <br> ACM Transactions on Sensor Networks;
		      <br> IEEE Pervasive Computing;  
		      <br> IEEE Internet of Things Journal; 
		      <br> Frontiers Artificial Intelligence of Things; </p>
		    <p> <b>Organization:</b> 
		     <br> 2022: Session Chair, MobiQuitous </p>
	    </div>

	    
	    

        <h1></h1>
        <h4> Miscellaneous </h4>
        <hr color=#F1ECEC size="1">
 <!--        <div class ="boxed">
        </div> -->
        <div class = "no_boxed">
        <div class="row no-gutters align-items-start">
          <div class ="col-3 col-md-3">
            <div class = "white_boxed">
              <img class="scale_img_100" src='data/images/auv-robosub copy.jpg'>
            </div>
          </div>
          <div class ="col-9 col-md-9">
            <div class = "white_boxed">

          <p>I had wonderful experiences on designing <strong> underwater robots (AUV)</strong> with <a href="data/images/auv-team.jpg" target="_blank" rel="noopener">a group of friends</a> during my undergraduate years, where I am in charge of the hardware and sonar system.
        Our AUV <a href="data/images/auv.jpg" target="_blank" rel="noopener">NEMO</a> won <strong>Best New Team</strong> in <a href="https://robonation.org/programs/robosub/" target="_blank" rel="noopener">Robosub</a> <a href="https://robosub.org/programs/2016-robosub/" target="_blank" rel="noopener">2016</a> (San Diego, CA) and <strong>First Place</strong> in <a href="https://sauvc.org" target="_blank" rel="noopener">SAUVC</a> <a href="https://sites.google.com/site/singaporeauvc/news/untitledpost" target="_blank" rel="noopener">2016</a> (Singapore). </p>

        	<p> Here are some memorable videos about our robot and team in SAUVC (<a href="https://www.youtube.com/watch?v=cbLnWk_7bbQ" target="_blank" rel="noopener">day3</a>, <a href="https://www.youtube.com/watch?v=rAqqL6XG_6Q" target="_blank" rel="noopener">day2</a>, <a href="https://www.youtube.com/watch?v=r6EPuCuPEJ8" target="_blank" rel="noopener">day1</a>) and Robosub (<a href = "https://www.youtube.com/watch?v=N81MyGFAt6I&feature=youtu.be" target="_blank" rel="noopener">team</a>).</p>
        </div>
      </div>
    </div>
  </div>
        <!-- https://www.onr.navy.mil/en/Media-Center/Press-Releases/2016/RoboSub-2016 -->
             
        
	    

    <h1></h1> 
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  

  </body>
</html>











